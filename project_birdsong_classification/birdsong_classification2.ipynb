{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# British Birdsong Classification Using CNN on the Spectrogram Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project is aiming at identifying the genus of a bird from 66 different genuses using a CNN model on the spectrogram images of the bird songs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-20T08:06:14.924772Z",
     "start_time": "2019-03-20T08:06:13.739650Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import soundfile as sf\n",
    "import re\n",
    "import librosa\n",
    "import librosa.display\n",
    "from tqdm import tqdm\n",
    "import sklearn\n",
    "import keras\n",
    "import keras.layers as layers\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-20T08:06:15.128618Z",
     "start_time": "2019-03-20T08:06:15.004504Z"
    }
   },
   "outputs": [],
   "source": [
    "path = './british-birdsong-dataset/songs/'\n",
    "files= os.listdir(path)\n",
    "nfile = len(files);\n",
    "meta = pd.read_csv('./british-birdsong-dataset/birdsong_metadata.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Constructing Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-20T08:06:15.566298Z",
     "start_time": "2019-03-20T08:06:15.564089Z"
    }
   },
   "outputs": [],
   "source": [
    "def index(filename_):\n",
    "    '''returns the index of the filename in metadata'''\n",
    "    return np.where(meta.file_id == np.int(re.findall('\\d+', filename_)[0]))[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-20T08:06:15.951171Z",
     "start_time": "2019-03-20T08:06:15.942396Z"
    }
   },
   "outputs": [],
   "source": [
    "def boostrap_sample(song_, num, rs, tclip):\n",
    "    '''sample num clips from song_ '''\n",
    "    spcs = []\n",
    "    \n",
    "    for j in range(num):\n",
    "        pstart = np.random.randint(len(song_) - tclip*rs)\n",
    "        pend = pstart + tclip*rs\n",
    "        clip = song_[pstart:pend]\n",
    "        \n",
    "        # construct spectrograms for clips\n",
    "        X = librosa.stft(clip, n_fft=100, hop_length=5000)\n",
    "        # Xdb = librosa.amplitude_to_db(abs(X))\n",
    "        \n",
    "        spcs.append(abs(X))\n",
    "    \n",
    "    spcs = np.array(spcs)\n",
    "        \n",
    "    return spcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-20T08:06:16.355444Z",
     "start_time": "2019-03-20T08:06:16.350327Z"
    }
   },
   "outputs": [],
   "source": [
    "time_clip = 20;\n",
    "npick = 100;\n",
    "train_set = [];\n",
    "valid_set = [];\n",
    "test_set = [];\n",
    "genuses_train = [];\n",
    "genuses_valid = [];\n",
    "genuses_test = [];\n",
    "count_cnames = {}; \n",
    "cnames_train = [];\n",
    "cnames_valid = [];\n",
    "cnames_test = [];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-20T08:07:34.939769Z",
     "start_time": "2019-03-20T08:06:16.740999Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 264/264 [01:18<00:00,  3.29it/s]\n"
     ]
    }
   ],
   "source": [
    "# specs = np.zeros((npick*251, 51, 89), dtype = np.float32)\n",
    "specs_train = []\n",
    "specs_test = []\n",
    "genuses_train = []\n",
    "genuses_test = []\n",
    "count_cnames = []\n",
    "\n",
    "count = 0\n",
    "\n",
    "for k in tqdm(range(nfile)):\n",
    "    \n",
    "    filename = files[k]\n",
    "    song, Fs = sf.read(path+filename)\n",
    "    T = len(song)/Fs\n",
    "    \n",
    "    if T < time_clip:\n",
    "        continue\n",
    "        \n",
    "    genus = meta.genus[index(filename)]\n",
    "    cname = meta.english_cname[index(filename)];\n",
    "    count_cnames.append(cname)\n",
    "\n",
    "    if count_cnames.count(cname) < 3:\n",
    "        genuses_train.extend([genus]*npick);\n",
    "        specs_train.extend(boostrap_sample(song, npick, Fs, time_clip))\n",
    "    else:\n",
    "        genuses_test.extend([genus]*npick);\n",
    "        specs_test.extend(boostrap_sample(song, npick, Fs, time_clip))\n",
    "    \n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-20T08:08:27.041587Z",
     "start_time": "2019-03-20T08:08:26.791970Z"
    }
   },
   "outputs": [],
   "source": [
    "specs_train = np.array(specs_train)\n",
    "specs_test = np.array(specs_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.  Transform datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-20T08:08:29.067310Z",
     "start_time": "2019-03-20T08:08:27.770102Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# rescale images to [0,1]\n",
    "\n",
    "data_train = np.reshape(specs_train, (len(specs_train), -1))\n",
    "data_test = np.reshape(specs_test, (len(specs_test), -1))\n",
    "\n",
    "data_train = sklearn.preprocessing.minmax_scale(data_train, axis=1)\n",
    "data_test = sklearn.preprocessing.minmax_scale(data_test, axis=1)\n",
    "\n",
    "specs_train_rescale = np.reshape(data_train, (len(specs_train), 51, 177,1))\n",
    "specs_test_rescale = np.reshape(data_test, (len(specs_test), 51, 177,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-20T08:08:29.805672Z",
     "start_time": "2019-03-20T08:08:29.759214Z"
    }
   },
   "outputs": [],
   "source": [
    "# change elements of labels to number vectors\n",
    "\n",
    "list_genus = np.unique(genuses_train)\n",
    "\n",
    "num_labels_train = []\n",
    "num_labels_test = []\n",
    "\n",
    "for genus in genuses_train:\n",
    "    num_labels_train.append(np.where(genus==list_genus)[0][0])\n",
    "    \n",
    "for genus in genuses_test:\n",
    "    num_labels_test.append(np.where(genus==list_genus)[0][0])\n",
    "    \n",
    "labels_train = np.zeros((len(genuses_train), len(list_genus)))\n",
    "labels_test = np.zeros((len(genuses_test), len(list_genus)))\n",
    "\n",
    "for j in range(len(labels_train)):\n",
    "    labels_train[j, num_labels_train[j]] = 1\n",
    "    \n",
    "for j in range(len(labels_test)):\n",
    "    labels_test[j, num_labels_test[j]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-20T08:08:30.683682Z",
     "start_time": "2019-03-20T08:08:30.679592Z"
    }
   },
   "outputs": [],
   "source": [
    "# divide training validation and test\n",
    "\n",
    "x_train = specs_train_rescale[0:np.int(0.8*len(specs_train))]\n",
    "x_valid = specs_train_rescale[np.int(0.8*len(specs_train)):]\n",
    "x_test = specs_test_rescale\n",
    "\n",
    "y_train = labels_train[0:np.int(0.8*len(specs_train))]\n",
    "y_valid = labels_train[np.int(0.8*len(specs_train)):]\n",
    "y_test = labels_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-18T06:34:06.440957Z",
     "start_time": "2019-03-18T06:34:06.436209Z"
    }
   },
   "source": [
    "## 4. Train Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-20T08:08:31.924977Z",
     "start_time": "2019-03-20T08:08:31.787248Z"
    }
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(filters=6, kernel_size=(3, 3), activation='relu', input_shape=(51,177,1)))\n",
    "model.add(layers.MaxPooling2D())\n",
    "\n",
    "model.add(layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D())\n",
    "\n",
    "model.add(layers.Dropout(0.4))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "model.add(layers.Dense(units=120, activation='relu'))\n",
    "\n",
    "model.add(layers.Dropout(0.4))\n",
    "\n",
    "model.add(layers.Dense(units=84, activation='relu'))\n",
    "\n",
    "model.add(layers.Dense(units=66, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-20T08:08:32.980566Z",
     "start_time": "2019-03-20T08:08:32.977507Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 49, 175, 6)        60        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 24, 87, 6)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 22, 85, 16)        880       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 11, 42, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 11, 42, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 7392)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 120)               887160    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 66)                5610      \n",
      "=================================================================\n",
      "Total params: 903,874\n",
      "Trainable params: 903,874\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-20T08:08:34.088840Z",
     "start_time": "2019-03-20T08:08:34.071164Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(loss='mse', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-20T08:09:29.190612Z",
     "start_time": "2019-03-20T08:08:35.197025Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 13120 samples, validate on 3280 samples\n",
      "Epoch 1/30\n",
      "13120/13120 [==============================] - 12s 883us/step - loss: 0.0146 - val_loss: 0.0151\n",
      "Epoch 2/30\n",
      "13120/13120 [==============================] - 1s 98us/step - loss: 0.0128 - val_loss: 0.0167\n",
      "Epoch 3/30\n",
      "13120/13120 [==============================] - 1s 99us/step - loss: 0.0110 - val_loss: 0.0175\n",
      "Epoch 4/30\n",
      "13120/13120 [==============================] - 1s 101us/step - loss: 0.0096 - val_loss: 0.0178\n",
      "Epoch 5/30\n",
      "13120/13120 [==============================] - 1s 103us/step - loss: 0.0086 - val_loss: 0.0183\n",
      "Epoch 6/30\n",
      "13120/13120 [==============================] - 1s 99us/step - loss: 0.0078 - val_loss: 0.0180\n",
      "Epoch 7/30\n",
      "13120/13120 [==============================] - 1s 112us/step - loss: 0.0072 - val_loss: 0.0183\n",
      "Epoch 8/30\n",
      "13120/13120 [==============================] - 1s 112us/step - loss: 0.0067 - val_loss: 0.0184\n",
      "Epoch 9/30\n",
      "13120/13120 [==============================] - 1s 112us/step - loss: 0.0063 - val_loss: 0.0192\n",
      "Epoch 10/30\n",
      "13120/13120 [==============================] - 1s 112us/step - loss: 0.0059 - val_loss: 0.0184\n",
      "Epoch 11/30\n",
      "13120/13120 [==============================] - 1s 113us/step - loss: 0.0055 - val_loss: 0.0187\n",
      "Epoch 12/30\n",
      "13120/13120 [==============================] - 2s 116us/step - loss: 0.0052 - val_loss: 0.0197\n",
      "Epoch 13/30\n",
      "13120/13120 [==============================] - 1s 110us/step - loss: 0.0050 - val_loss: 0.0194\n",
      "Epoch 14/30\n",
      "13120/13120 [==============================] - 1s 112us/step - loss: 0.0047 - val_loss: 0.0193\n",
      "Epoch 15/30\n",
      "13120/13120 [==============================] - 1s 112us/step - loss: 0.0045 - val_loss: 0.0190\n",
      "Epoch 16/30\n",
      "13120/13120 [==============================] - 1s 113us/step - loss: 0.0042 - val_loss: 0.0193\n",
      "Epoch 17/30\n",
      "13120/13120 [==============================] - 2s 116us/step - loss: 0.0040 - val_loss: 0.0195\n",
      "Epoch 18/30\n",
      "13120/13120 [==============================] - 1s 112us/step - loss: 0.0038 - val_loss: 0.0191\n",
      "Epoch 19/30\n",
      "13120/13120 [==============================] - 1s 112us/step - loss: 0.0037 - val_loss: 0.0192\n",
      "Epoch 20/30\n",
      "13120/13120 [==============================] - 1s 112us/step - loss: 0.0034 - val_loss: 0.0190\n",
      "Epoch 21/30\n",
      "13120/13120 [==============================] - 2s 117us/step - loss: 0.0033 - val_loss: 0.0190\n",
      "Epoch 22/30\n",
      "13120/13120 [==============================] - 1s 112us/step - loss: 0.0032 - val_loss: 0.0198\n",
      "Epoch 23/30\n",
      "13120/13120 [==============================] - 1s 108us/step - loss: 0.0031 - val_loss: 0.0194\n",
      "Epoch 24/30\n",
      "13120/13120 [==============================] - 2s 116us/step - loss: 0.0029 - val_loss: 0.0197\n",
      "Epoch 25/30\n",
      "13120/13120 [==============================] - 1s 111us/step - loss: 0.0029 - val_loss: 0.0192\n",
      "Epoch 26/30\n",
      "13120/13120 [==============================] - 1s 113us/step - loss: 0.0027 - val_loss: 0.0194\n",
      "Epoch 27/30\n",
      "13120/13120 [==============================] - 1s 111us/step - loss: 0.0027 - val_loss: 0.0201\n",
      "Epoch 28/30\n",
      "13120/13120 [==============================] - 1s 110us/step - loss: 0.0026 - val_loss: 0.0196\n",
      "Epoch 29/30\n",
      "13120/13120 [==============================] - 1s 114us/step - loss: 0.0026 - val_loss: 0.0194\n",
      "Epoch 30/30\n",
      "13120/13120 [==============================] - 2s 116us/step - loss: 0.0025 - val_loss: 0.0194\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2a60b7fef0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, validation_data=(x_valid, y_valid), epochs = 30, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-20T08:09:30.621054Z",
     "start_time": "2019-03-20T08:09:30.279752Z"
    }
   },
   "outputs": [],
   "source": [
    "predict_ = model.predict(x_test)\n",
    "predict = np.zeros((len(predict_[:,0]), len(predict_[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-20T08:09:31.808829Z",
     "start_time": "2019-03-20T08:09:31.707141Z"
    }
   },
   "outputs": [],
   "source": [
    "accuracy = 0\n",
    "for j in range(len(predict_[:,0])):\n",
    "    predict[j,:] = predict_[j] == np.max(predict_[j])\n",
    "    if (np.sum(predict[j] == y_test[j]) == len(predict[j])) == 1 :\n",
    "        accuracy += 1\n",
    "accuracy /= len(predict[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-20T08:09:33.024128Z",
     "start_time": "2019-03-20T08:09:33.021806Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35696428571428573"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "799.5px",
    "left": "622px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
