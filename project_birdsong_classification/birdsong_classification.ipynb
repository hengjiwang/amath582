{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# British Birdsong Classification Using CNN on the Spectrogram Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project is aiming at identifying the genus of a bird from 66 different genuses using a CNN model on the spectrogram images of the bird songs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-18T07:34:25.731919Z",
     "start_time": "2019-03-18T07:34:25.724089Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import soundfile as sf\n",
    "import re\n",
    "import librosa\n",
    "import librosa.display\n",
    "from tqdm import tqdm\n",
    "import sklearn\n",
    "import keras\n",
    "import keras.layers as layers\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-18T07:33:08.404256Z",
     "start_time": "2019-03-18T07:33:08.396901Z"
    }
   },
   "outputs": [],
   "source": [
    "path = './british-birdsong-dataset/songs/'\n",
    "files= os.listdir(path)\n",
    "nfile = len(files);\n",
    "meta = pd.read_csv('./british-birdsong-dataset/birdsong_metadata.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Constructing Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-18T07:33:08.646452Z",
     "start_time": "2019-03-18T07:33:08.644258Z"
    }
   },
   "outputs": [],
   "source": [
    "def index(filename_):\n",
    "    '''returns the index of the filename in metadata'''\n",
    "    return np.where(meta.file_id == np.int(re.findall('\\d+', filename_)[0]))[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-18T07:33:08.898029Z",
     "start_time": "2019-03-18T07:33:08.889367Z"
    }
   },
   "outputs": [],
   "source": [
    "def boostrap_sample(song_, num, rs, tclip):\n",
    "    '''sample num clips from song_ '''\n",
    "    spcs = []\n",
    "    \n",
    "    for j in range(num):\n",
    "        pstart = np.random.randint(len(song_) - tclip*rs)\n",
    "        pend = pstart + tclip*rs\n",
    "        clip = song_[pstart:pend]\n",
    "        \n",
    "        # construct spectrograms for clips\n",
    "        X = librosa.stft(clip, n_fft=100, hop_length=5000)\n",
    "        # Xdb = librosa.amplitude_to_db(abs(X))\n",
    "        \n",
    "        spcs.append(abs(X))\n",
    "    \n",
    "    spcs = np.array(spcs)\n",
    "        \n",
    "    return spcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-18T07:33:09.139283Z",
     "start_time": "2019-03-18T07:33:09.135127Z"
    }
   },
   "outputs": [],
   "source": [
    "time_clip = 10;\n",
    "npick = 100;\n",
    "train_set = [];\n",
    "valid_set = [];\n",
    "test_set = [];\n",
    "genuses_train = [];\n",
    "genuses_valid = [];\n",
    "genuses_test = [];\n",
    "count_cnames = {}; \n",
    "cnames_train = [];\n",
    "cnames_valid = [];\n",
    "cnames_test = [];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-18T07:33:46.276623Z",
     "start_time": "2019-03-18T07:33:09.388512Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 264/264 [00:36<00:00,  8.21it/s]\n"
     ]
    }
   ],
   "source": [
    "specs = np.zeros((npick*nfile, 51, 89), dtype = np.float32)\n",
    "genuses = []\n",
    "cnames = []\n",
    "\n",
    "count = 0\n",
    "\n",
    "for k in tqdm(range(nfile)):\n",
    "    filename = files[k]\n",
    "    song, Fs = sf.read(path+filename)\n",
    "    T = len(song)/Fs\n",
    "    \n",
    "    genus = meta.genus[index(filename)]\n",
    "    cname = meta.english_cname[index(filename)];\n",
    "    genuses.extend([genus]*npick)\n",
    "    cnames.extend([cname]*npick)\n",
    "    \n",
    "    if T < time_clip:\n",
    "        continue\n",
    "    \n",
    "#     # build dictionary for bird names\n",
    "#     if cname in count_cnames:\n",
    "#         count_cnames[cname] += 1\n",
    "#     else:\n",
    "#         count_cnames[cname] = 1\n",
    "    \n",
    "    specs[k*npick:k*npick+npick,:,:] = boostrap_sample(song, npick, Fs, time_clip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Divide Training/Validation/Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-18T07:33:51.107858Z",
     "start_time": "2019-03-18T07:33:49.662797Z"
    }
   },
   "outputs": [],
   "source": [
    "# remove black images\n",
    "\n",
    "inds = []\n",
    "\n",
    "for j in range(len(specs)):\n",
    "    if sum(sum(specs[j]==0))==51*89:\n",
    "        inds.append(j)\n",
    "\n",
    "specs = np.delete(specs, inds, axis=0)\n",
    "genuses = np.delete(np.array(genuses), inds)\n",
    "cnames =np.delete(np.array(cnames), inds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-18T07:34:11.967644Z",
     "start_time": "2019-03-18T07:34:11.807285Z"
    }
   },
   "outputs": [],
   "source": [
    "# shuffle the datasets in the same way\n",
    "\n",
    "inds = np.arange(0, len(specs), 1)\n",
    "inds = np.random.permutation(inds)\n",
    "\n",
    "specs = specs[inds, :, :]\n",
    "genuses = genuses[inds]\n",
    "cnames = cnames[inds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-18T07:38:44.416487Z",
     "start_time": "2019-03-18T07:38:43.615872Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# rescale images to [0,1]\n",
    "\n",
    "data_mat = np.reshape(specs, (len(specs), -1))\n",
    "data_mat = sklearn.preprocessing.minmax_scale(data_mat, axis=1)\n",
    "specs_rescale = np.reshape(data_mat, (len(specs), 51, 89,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-18T07:38:45.750608Z",
     "start_time": "2019-03-18T07:38:45.745424Z"
    }
   },
   "outputs": [],
   "source": [
    "# divide training validation and test\n",
    "\n",
    "x_train = specs_rescale[0:np.int(0.6*len(specs))]\n",
    "x_valid = specs_rescale[np.int(0.6*len(specs)):np.int(0.8*len(specs))]\n",
    "x_test = specs_rescale[np.int(0.8*len(specs)):]\n",
    "\n",
    "y_train = genuses[0:np.int(0.6*len(specs))]\n",
    "y_valid = genuses[np.int(0.6*len(specs)):np.int(0.8*len(specs))]\n",
    "y_test = genuses[np.int(0.8*len(specs)):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-18T06:34:06.440957Z",
     "start_time": "2019-03-18T06:34:06.436209Z"
    }
   },
   "source": [
    "## 4. Train Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-18T07:38:09.611762Z",
     "start_time": "2019-03-18T07:38:09.547274Z"
    }
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(filters=6, kernel_size=(3, 3), activation='relu', input_shape=(51,89,1)))\n",
    "model.add(layers.MaxPooling2D())\n",
    "\n",
    "model.add(layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D())\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "model.add(layers.Dense(units=120, activation='relu'))\n",
    "\n",
    "model.add(layers.Dense(units=84, activation='relu'))\n",
    "\n",
    "model.add(layers.Dense(units=66, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-18T07:39:33.617979Z",
     "start_time": "2019-03-18T07:39:33.614282Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 49, 87, 6)         60        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 24, 43, 6)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 22, 41, 16)        880       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 11, 20, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 3520)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 120)               422520    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 66)                5610      \n",
      "=================================================================\n",
      "Total params: 439,234\n",
      "Trainable params: 439,234\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-18T07:39:04.153138Z",
     "start_time": "2019-03-18T07:39:04.134923Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(loss='mse', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-18T07:39:04.898316Z",
     "start_time": "2019-03-18T07:39:04.885687Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected dense_6 to have shape (66,) but got array with shape (1,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-a7ba1ce7bd20>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/hengji/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m    953\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/hengji/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0mfeed_output_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m                 exception_prefix='target')\n\u001b[0m\u001b[1;32m    790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/hengji/anaconda3/lib/python3.6/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    136\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    139\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking target: expected dense_6 to have shape (66,) but got array with shape (1,)"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train, validation_data=(x_valid, y_valid), epochs = 30, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "799.5px",
    "left": "622px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
