{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# British Birdsong Classification Using CNN on the Spectrogram Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project is aiming at identifying the genus of a bird from 66 different genuses using a CNN model on the spectrogram images of the bird songs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-20T05:59:23.562491Z",
     "start_time": "2019-03-20T05:59:22.337848Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import soundfile as sf\n",
    "import re\n",
    "import librosa\n",
    "import librosa.display\n",
    "from tqdm import tqdm\n",
    "import sklearn\n",
    "import keras\n",
    "import keras.layers as layers\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-20T05:59:23.640885Z",
     "start_time": "2019-03-20T05:59:23.632661Z"
    }
   },
   "outputs": [],
   "source": [
    "path = './british-birdsong-dataset/songs/'\n",
    "files= os.listdir(path)\n",
    "nfile = len(files);\n",
    "meta = pd.read_csv('./british-birdsong-dataset/birdsong_metadata.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Constructing Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-20T05:59:23.981404Z",
     "start_time": "2019-03-20T05:59:23.979264Z"
    }
   },
   "outputs": [],
   "source": [
    "def index(filename_):\n",
    "    '''returns the index of the filename in metadata'''\n",
    "    return np.where(meta.file_id == np.int(re.findall('\\d+', filename_)[0]))[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-20T05:59:24.348917Z",
     "start_time": "2019-03-20T05:59:24.340352Z"
    }
   },
   "outputs": [],
   "source": [
    "def boostrap_sample(song_, num, rs, tclip):\n",
    "    '''sample num clips from song_ '''\n",
    "    spcs = []\n",
    "    \n",
    "    for j in range(num):\n",
    "        pstart = np.random.randint(len(song_) - tclip*rs)\n",
    "        pend = pstart + tclip*rs\n",
    "        clip = song_[pstart:pend]\n",
    "        \n",
    "        # construct spectrograms for clips\n",
    "        X = librosa.stft(clip, n_fft=100, hop_length=5000)\n",
    "        # Xdb = librosa.amplitude_to_db(abs(X))\n",
    "        \n",
    "        spcs.append(abs(X))\n",
    "    \n",
    "    spcs = np.array(spcs)\n",
    "        \n",
    "    return spcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-20T07:32:59.054685Z",
     "start_time": "2019-03-20T07:32:59.012594Z"
    }
   },
   "outputs": [],
   "source": [
    "time_clip = 20;\n",
    "npick = 100;\n",
    "train_set = [];\n",
    "valid_set = [];\n",
    "test_set = [];\n",
    "genuses_train = [];\n",
    "genuses_valid = [];\n",
    "genuses_test = [];\n",
    "count_cnames = {}; \n",
    "cnames_train = [];\n",
    "cnames_valid = [];\n",
    "cnames_test = [];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-20T07:34:30.206071Z",
     "start_time": "2019-03-20T07:33:01.035931Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 264/264 [01:29<00:00,  2.96it/s]\n"
     ]
    }
   ],
   "source": [
    "# specs = np.zeros((npick*251, 51, 89), dtype = np.float32)\n",
    "specs_train = []\n",
    "specs_test = []\n",
    "genuses_train = []\n",
    "genuses_test = []\n",
    "count_cnames = []\n",
    "\n",
    "count = 0\n",
    "\n",
    "for k in tqdm(range(nfile)):\n",
    "    \n",
    "    filename = files[k]\n",
    "    song, Fs = sf.read(path+filename)\n",
    "    T = len(song)/Fs\n",
    "    \n",
    "    if T < time_clip:\n",
    "        continue\n",
    "        \n",
    "    genus = meta.genus[index(filename)]\n",
    "    cname = meta.english_cname[index(filename)];\n",
    "    count_cnames.append(cname)\n",
    "\n",
    "    if count_cnames.count(cname) < 3:\n",
    "        genuses_train.extend([genus]*npick);\n",
    "        specs_train.extend(boostrap_sample(song, npick, Fs, time_clip))\n",
    "    else:\n",
    "        genuses_test.extend([genus]*npick);\n",
    "        specs_test.extend(boostrap_sample(song, npick, Fs, time_clip))\n",
    "    \n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-20T07:35:35.303629Z",
     "start_time": "2019-03-20T07:35:34.942136Z"
    }
   },
   "outputs": [],
   "source": [
    "specs_train = np.array(specs_train)\n",
    "specs_test = np.array(specs_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.  Transform datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-20T07:38:51.418493Z",
     "start_time": "2019-03-20T07:38:07.305401Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# rescale images to [0,1]\n",
    "\n",
    "data_train = np.reshape(specs_train, (len(specs_train), -1))\n",
    "data_test = np.reshape(specs_test, (len(specs_test), -1))\n",
    "\n",
    "data_train = sklearn.preprocessing.minmax_scale(data_train, axis=1)\n",
    "data_test = sklearn.preprocessing.minmax_scale(data_test, axis=1)\n",
    "\n",
    "specs_train_rescale = np.reshape(data_train, (len(specs_train), 51, 442,1))\n",
    "specs_test_rescale = np.reshape(data_test, (len(specs_test), 51, 442,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-20T08:04:04.394467Z",
     "start_time": "2019-03-20T08:04:04.291867Z"
    }
   },
   "outputs": [],
   "source": [
    "# change elements of labels to number vectors\n",
    "\n",
    "list_genus = np.unique(genuses_train)\n",
    "\n",
    "num_labels_train = []\n",
    "num_labels_test = []\n",
    "\n",
    "for genus in genuses_train:\n",
    "    num_labels_train.append(np.where(genus==list_genus)[0][0])\n",
    "    \n",
    "for genus in genuses_test:\n",
    "    num_labels_test.append(np.where(genus==list_genus)[0][0])\n",
    "    \n",
    "labels_train = np.zeros((len(genuses_train), len(list_genus)))\n",
    "labels_test = np.zeros((len(genuses_test), len(list_genus)))\n",
    "\n",
    "for j in range(len(labels_train)):\n",
    "    labels_train[j, num_labels_train[j]] = 1\n",
    "    \n",
    "for j in range(len(labels_test)):\n",
    "    labels_test[j, num_labels_test[j]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-20T08:04:05.720139Z",
     "start_time": "2019-03-20T08:04:05.711692Z"
    }
   },
   "outputs": [],
   "source": [
    "# divide training validation and test\n",
    "\n",
    "x_train = specs_train_rescale[0:np.int(0.8*len(specs_train))]\n",
    "x_valid = specs_train_rescale[np.int(0.8*len(specs_train)):]\n",
    "x_test = specs_test_rescale\n",
    "\n",
    "y_train = labels_train[0:np.int(0.8*len(specs_train))]\n",
    "y_valid = labels_train[np.int(0.8*len(specs_train)):]\n",
    "y_test = labels_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-18T06:34:06.440957Z",
     "start_time": "2019-03-18T06:34:06.436209Z"
    }
   },
   "source": [
    "## 4. Train Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-20T08:04:20.262854Z",
     "start_time": "2019-03-20T08:04:20.185520Z"
    }
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(filters=6, kernel_size=(3, 3), activation='relu', input_shape=(51,442,1)))\n",
    "model.add(layers.MaxPooling2D())\n",
    "\n",
    "model.add(layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D())\n",
    "\n",
    "model.add(layers.Dropout(0.4))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "model.add(layers.Dense(units=120, activation='relu'))\n",
    "\n",
    "model.add(layers.Dropout(0.4))\n",
    "\n",
    "model.add(layers.Dense(units=84, activation='relu'))\n",
    "\n",
    "model.add(layers.Dense(units=66, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-20T08:04:21.146491Z",
     "start_time": "2019-03-20T08:04:21.141919Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_12 (Conv2D)           (None, 49, 440, 6)        60        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 24, 220, 6)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 22, 218, 16)       880       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 11, 109, 16)       0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 11, 109, 16)       0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 19184)             0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 120)               2302200   \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 66)                5610      \n",
      "=================================================================\n",
      "Total params: 2,318,914\n",
      "Trainable params: 2,318,914\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-20T08:04:22.024981Z",
     "start_time": "2019-03-20T08:04:22.008121Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(loss='mse', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-20T08:04:22.864520Z",
     "start_time": "2019-03-20T08:04:22.855472Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected dense_15 to have shape (66,) but got array with shape (54,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-a7ba1ce7bd20>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/hengji/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m    953\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/hengji/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0mfeed_output_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m                 exception_prefix='target')\n\u001b[0m\u001b[1;32m    790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0;31m# Generate sample-wise weight values given the `sample_weight` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/hengji/anaconda3/lib/python3.6/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    136\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    139\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking target: expected dense_15 to have shape (66,) but got array with shape (54,)"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train, validation_data=(x_valid, y_valid), epochs = 30, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-20T08:04:22.877657Z",
     "start_time": "2019-03-20T08:04:21.637Z"
    }
   },
   "outputs": [],
   "source": [
    "predict_ = model.predict(x_test)\n",
    "predict = np.zeros((len(predict_[:,0]), len(predict_[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-20T08:04:22.891206Z",
     "start_time": "2019-03-20T08:04:22.165Z"
    }
   },
   "outputs": [],
   "source": [
    "accuracy = 0\n",
    "for j in range(len(predict_[:,0])):\n",
    "    predict[j,:] = predict_[j] == np.max(predict_[j])\n",
    "    if (np.sum(predict[j] == y_test[j]) == len(predict[j])) == 1 :\n",
    "        accuracy += 1\n",
    "accuracy /= len(predict[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-20T08:04:10.030374Z",
     "start_time": "2019-03-20T08:04:06.701Z"
    }
   },
   "outputs": [],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "799.5px",
    "left": "622px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
